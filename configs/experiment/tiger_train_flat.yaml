# @package _global_
data_dir: ???
semantic_id_path: ???
num_hierarchies: ???
sequence_length: 120

task_name: train
id: ${now:%Y-%m-%d}/${now:%H-%M-%S}
tags:
- amazon-p5-gr-train
train: true
test: true
ckpt_path: null
seed: 42
data_loading:
  features_config:
    features:
    - name: sequence_data
      num_placeholder_tokens: 0
      semantic_ids: ???
      is_item_ids: true
      type:
        _target_: torch.__dict__.get
        _args_:
        - int32
    - name: embedding
      type:
        _target_: torch.__dict__.get
        _args_:
        - float32
    - name: text
      type:
        _target_: torch.__dict__.get
        _args_:
        - bytes
    - name: user_id
      is_item_ids: true
      type:
        _target_: torch.__dict__.get
        _args_:
        - int32
  dataset_config:
    dataset:
      _target_: src.data.loading.components.interfaces.SemanticIDDatasetConfig
      user_id_field: user_id
      min_sequence_length: 1
      iterate_per_row: true
      keep_user_id: true
      features_to_consider: ${extract_fields_from_list_of_dicts:${data_loading.features_config.features},
        "name", False, "is_item_ids", "True"}
      num_placeholder_tokens_map: ${create_map_from_list_of_dicts:${data_loading.features_config.features},
        "name", "num_placeholder_tokens"}
      semantic_id_map: ${create_map_from_list_of_dicts:${data_loading.features_config.features},
        "name", "semantic_ids"}
      data_iterator:
        _target_: src.data.loading.components.iterators.TFRecordIterator
      preprocessing_functions:
      - _target_: src.data.loading.components.pre_processing.filter_features_to_consider
        _partial_: true
      - _target_: src.data.loading.components.pre_processing.convert_to_dense_numpy_array
        _partial_: true
      - _target_: src.data.loading.components.pre_processing.convert_fields_to_tensors
        _partial_: true
      - _target_: src.data.loading.components.pre_processing.map_sparse_id_to_semantic_id
        _partial_: true
        features_to_apply:
        - sequence_data
        num_hierarchies: ${model.num_hierarchies}
  train_dataloader_config:
    dataloader:
      _target_: src.data.loading.components.interfaces.SequenceDataloaderConfig
      dataset_class:
        _target_: src.data.loading.components.dataloading.UnboundedSequenceIterable
        _partial_: true
      data_folder: ${paths.data_dir}/training
      should_shuffle_rows: true
      labels:
        sequence_data:
          transform:
            _target_: src.data.loading.components.label_function.NextKTokenMasking
            next_k: ${model.num_hierarchies}
      batch_size_per_device: 32
      num_workers: 8
      timeout: 60
      assign_files_by_size: false
      oov_token: null
      masking_token: -1
      sequence_length: ${sequence_length}
      padding_token: -1
      drop_last: true
      persistent_workers: true
      collate_fn:
        _target_: src.data.loading.components.collate_functions.collate_with_sid_causal_duplicate
        _partial_: true
        sequence_length: ${data_loading.train_dataloader_config.dataloader.sequence_length}
        padding_token: ${data_loading.train_dataloader_config.dataloader.padding_token}
        sequence_field_name: sequence_data
        sid_hierarchy: ${model.num_hierarchies}
        max_batch_size: 512
      dataset_config:
        _target_: src.data.loading.components.interfaces.SemanticIDDatasetConfig
        user_id_field: user_id
        min_sequence_length: 1
        iterate_per_row: true
        keep_user_id: true
        features_to_consider: ${extract_fields_from_list_of_dicts:${data_loading.features_config.features},
          "name", False, "is_item_ids", "True"}
        num_placeholder_tokens_map: ${create_map_from_list_of_dicts:${data_loading.features_config.features},
          "name", "num_placeholder_tokens"}
        semantic_id_map:
          sequence_data:
            _target_: torch.load
            _args_:
            - _target_: src.utils.file_utils.open_local_or_remote
              file_path: ${semantic_id_path}
              mode: rb
        data_iterator:
          _target_: src.data.loading.components.iterators.TFRecordIterator
        preprocessing_functions:
        - _target_: src.data.loading.components.pre_processing.filter_features_to_consider
          _partial_: true
        - _target_: src.data.loading.components.pre_processing.convert_to_dense_numpy_array
          _partial_: true
        - _target_: src.data.loading.components.pre_processing.convert_fields_to_tensors
          _partial_: true
        - _target_: src.data.loading.components.pre_processing.map_sparse_id_to_semantic_id
          _partial_: true
          features_to_apply:
          - sequence_data
          num_hierarchies: ${model.num_hierarchies}
      assign_all_files_per_worker: true
  val_dataloader_config:
    dataloader:
      _target_: src.data.loading.components.interfaces.SequenceDataloaderConfig
      dataset_class:
        _target_: src.data.loading.components.dataloading.UnboundedSequenceIterable
        _partial_: true
      data_folder: ${paths.data_dir}/evaluation
      should_shuffle_rows: false
      labels:
        sequence_data:
          transform:
            _target_: src.data.loading.components.label_function.NextKTokenMasking
            next_k: ${model.num_hierarchies}
      batch_size_per_device: 8
      num_workers: 8
      timeout: 60
      assign_files_by_size: true
      oov_token: ${data_loading.train_dataloader_config.dataloader.oov_token}
      masking_token: ${data_loading.train_dataloader_config.dataloader.masking_token}
      sequence_length: ${data_loading.train_dataloader_config.dataloader.sequence_length}
      padding_token: ${data_loading.train_dataloader_config.dataloader.padding_token}
      drop_last: false
      persistent_workers: false
      collate_fn:
        _target_: src.data.loading.components.collate_functions.collate_fn_train
        _partial_: true
        sequence_length: ${data_loading.train_dataloader_config.dataloader.sequence_length}
        padding_token: ${data_loading.train_dataloader_config.dataloader.padding_token}
      dataset_config: ${data_loading.train_dataloader_config.dataloader.dataset_config}
      pin_memory: false
  test_dataloader_config:
    dataloader:
      _target_: src.data.loading.components.interfaces.SequenceDataloaderConfig
      dataset_class:
        _target_: src.data.loading.components.dataloading.UnboundedSequenceIterable
        _partial_: true
      data_folder: ${paths.data_dir}/testing
      should_shuffle_rows: false
      labels:
        sequence_data:
          transform:
            _target_: src.data.loading.components.label_function.NextKTokenMasking
            next_k: ${model.num_hierarchies}
      batch_size_per_device: 8
      num_workers: 8
      timeout: 60
      assign_files_by_size: true
      oov_token: ${data_loading.train_dataloader_config.dataloader.oov_token}
      masking_token: ${data_loading.train_dataloader_config.dataloader.masking_token}
      sequence_length: ${data_loading.train_dataloader_config.dataloader.sequence_length}
      padding_token: ${data_loading.train_dataloader_config.dataloader.padding_token}
      drop_last: false
      persistent_workers: false
      collate_fn:
        _target_: src.data.loading.components.collate_functions.collate_fn_train
        _partial_: true
        sequence_length: ${data_loading.train_dataloader_config.dataloader.sequence_length}
        padding_token: ${data_loading.train_dataloader_config.dataloader.padding_token}
      dataset_config: ${data_loading.train_dataloader_config.dataloader.dataset_config}
      pin_memory: false
  datamodule:
    _target_: src.data.loading.datamodules.sequence_datamodule.SequenceDataModule
    train_dataloader_config: ${..train_dataloader_config.dataloader}
    val_dataloader_config: ${..val_dataloader_config.dataloader}
    test_dataloader_config: ${..test_dataloader_config.dataloader}
model:
  huggingface_model:
    _target_: transformers.T5EncoderModel
    config:
      _target_: transformers.T5Config
      vocab_size: 256
      d_model: 128
      num_heads: 6
      dropout_rate: 0.15
      d_ff: 1024
      d_kv: 64
      num_layers: 4
  _target_: src.models.modules.semantic_id.tiger_generation_model.SemanticIDEncoderDecoder
  feature_to_model_input_map:
    sequence_data: input_ids
    user_id: user_id
  postprocessor: null
  aggregator: null
  loss_function: ${loss.loss_function}
  optimizer: ${optim.optimizer}
  scheduler: ${optim.scheduler}
  evaluator: ${eval.evaluator}
  weight_tying: true
  compile: false
  decoder:
    _target_: transformers.models.t5.modeling_t5.T5Stack
    config:
      _target_: transformers.models.t5.configuration_t5.T5Config
      vocab_size: ${model.huggingface_model.config.vocab_size}
      d_model: ${model.huggingface_model.config.d_model}
      num_heads: ${model.huggingface_model.config.num_heads}
      dropout_rate: 0.15
      d_ff: ${model.huggingface_model.config.d_ff}
      d_kv: ${model.huggingface_model.config.d_kv}
      num_layers: 4
      is_decoder: true
      is_encoder_decoder: false
    embed_tokens:
      _target_: torch.nn.Embedding
      num_embeddings: ${model.huggingface_model.config.vocab_size}
      embedding_dim: ${model.huggingface_model.config.d_model}
  num_hierarchies: ${num_hierarchies}
  num_user_bins: null
  codebooks: ${data_loading.train_dataloader_config.dataloader.dataset_config.semantic_id_map.sequence_data}
  mlp_layers: 2
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: checkpoint_{epoch:03d}_{step:06d}
    monitor: val/recall@5
    verbose: true
    save_last: null
    save_top_k: 1
    mode: max
    auto_insert_metric_name: true
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: false
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: ${callbacks.model_checkpoint.monitor}
    min_delta: 0.0
    patience: 10
    verbose: true
    mode: ${callbacks.model_checkpoint.mode}
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: false
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: -1
  restart_job:
    _target_: src.utils.restart_job.RestartAndLoadCheckpointCallback
    metadata_dir: ${paths.metadata_dir}
logger:
  csv:
    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger
    save_dir: ${paths.output_dir}
    name: csv/
    prefix: ''
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_steps: 1
  max_steps: 320000
  max_epochs: 10
  accelerator: gpu
  devices: -1
  num_nodes: 1
  precision: bf16-mixed
  log_every_n_steps: 100
  val_check_interval: 1600
  deterministic: false
  accumulate_grad_batches: 16
  profiler:
    _target_: lightning.pytorch.profilers.PassThroughProfiler
  strategy: ddp
  sync_batchnorm: true
  num_sanity_val_steps: 0
  min_epochs: 0
paths:
  root_dir: .
  data_dir: ${data_dir}
  log_dir: ${paths.root_dir}/logs
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
  profile_dir: ${hydra:run.dir}/profile_output
  metadata_dir: ${paths.output_dir}/metadata
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config_warnings: true
  print_config: true
loss:
  loss_function:
    _target_: torch.nn.CrossEntropyLoss
optim:
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 0.0001
  scheduler: null
eval:
  evaluator:
    _target_: src.components.eval_metrics.SIDRetrievalEvaluator
    top_k_list:
    - 5
    - 10
    metrics:
      ndcg:
        _target_: src.components.eval_metrics.NDCG
        _partial_: true
      recall:
        _target_: src.components.eval_metrics.Recall
        _partial_: true

